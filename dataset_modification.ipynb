{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HhjxySW1SoBY","executionInfo":{"status":"ok","timestamp":1701152589497,"user_tz":480,"elapsed":17236,"user":{"displayName":"Austin Chen","userId":"06999593592342824043"}},"outputId":"8859a09d-1d06-4c77-a96e-a040871b506f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"id":"ARgBdcPJSSxK","executionInfo":{"status":"ok","timestamp":1701152827072,"user_tz":480,"elapsed":222,"user":{"displayName":"Austin Chen","userId":"06999593592342824043"}}},"outputs":[],"source":["import json\n","import os\n","import random"]},{"cell_type":"markdown","source":["For reproducibility, we fix the random seed."],"metadata":{"id":"Il2LYOAQlrEF"}},{"cell_type":"code","source":["seed = 42"],"metadata":{"id":"W8Yjv3GWlhGz","executionInfo":{"status":"ok","timestamp":1701152970422,"user_tz":480,"elapsed":167,"user":{"displayName":"Austin Chen","userId":"06999593592342824043"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# Creating New Datasets\n","\n","We seek to create new datasets by performing modifications on the old datasets or combining multiple datasets."],"metadata":{"id":"AJlnuaZqSqD1"}},{"cell_type":"code","source":["folder = '/content/drive/MyDrive/CS 171/Final Project'"],"metadata":{"id":"RmxtGZr9TFK_","executionInfo":{"status":"ok","timestamp":1701152767943,"user_tz":480,"elapsed":208,"user":{"displayName":"Austin Chen","userId":"06999593592342824043"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def load_dataset(filename):\n","  text = []\n","  labels = []\n","\n","  with open(os.path.join(folder, filename), 'r') as infile:\n","    for line in infile.readlines():\n","      sample = json.loads(line)\n","      text.append(sample['text'])\n","      labels.append(sample['sentiment'])\n","\n","  return text, labels\n","\n","\n","def save_dataset(text, labels, filename):\n","  with open(os.path.join(folder, filename), 'w') as outfile:\n","    for text_sample, label_sample in zip(text, labels):\n","      entry_dict = {'text': text_sample, 'sentiment': label_sample}\n","      json.dump(entry_dict, outfile)\n","      outfile.write('\\n')"],"metadata":{"id":"ly0Tig0NTBN3","executionInfo":{"status":"ok","timestamp":1701152773489,"user_tz":480,"elapsed":191,"user":{"displayName":"Austin Chen","userId":"06999593592342824043"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":30,"metadata":{"id":"CCeFrbIGSSxU","executionInfo":{"status":"ok","timestamp":1701153507977,"user_tz":480,"elapsed":187,"user":{"displayName":"Austin Chen","userId":"06999593592342824043"}}},"outputs":[],"source":["def reverse_dataset(dataset_filename, output_filename):\n","  text, labels = load_dataset(dataset_filename)\n","\n","  # Reverse each of the sentences\n","  for text_sample in text:\n","    text_sample.reverse()\n","\n","  save_dataset(text, labels, output_filename)\n","\n","  # Sample first line to check for consistency\n","  print('Sampling reversed dataset')\n","  print(text[0], labels[0])\n","\n","\n","def shuffle_dataset(dataset_filename, output_filename):\n","  # Set seed so each shuffle is the same\n","  random.seed(seed)\n","\n","  text, labels = load_dataset(dataset_filename)\n","\n","  # Reverse each of the sentences\n","  for text_sample in text:\n","    random.shuffle(text_sample)\n","\n","  save_dataset(text, labels, output_filename)\n","\n","  # Sample first line to check for consistency\n","  print('Sampling shuffled dataset')\n","  print(text[0], labels[0])\n","\n","\n","def truncate_dataset(ratio, dataset_filename, output_filename):\n","  text, labels = load_dataset(dataset_filename)\n","\n","  output_text, output_labels = [], []\n","\n","  # Take 1 in every ratio samples from the dataset\n","  for index, text_sample in enumerate(text):\n","    if index % ratio == 0:\n","      output_text.append(text_sample)\n","      output_labels.append(labels[index])\n","\n","  save_dataset(output_text, output_labels, output_filename)\n","\n","  # Sample first line to check for consistency\n","  print('Sampling truncated dataset')\n","  print(output_text[0], output_labels[0])\n","  print(f'Comparing sizes, Before: {len(text)}, After: {len(output_text)}')\n","\n","\n","def combine_datasets_2(dataset1_filename, dataset2_filename, output_filename):\n","  text1, labels1 = load_dataset(dataset1_filename)\n","  text2, labels2 = load_dataset(dataset2_filename)\n","\n","  text, labels = [], []\n","  # Take alternating samples from both datasets until one runs out\n","  for index in range(min(len(text1), len(text2))):\n","    if index % 2 == 0:\n","      text.append(text1[index])\n","      labels.append(labels1[index])\n","    else:\n","      text.append(text2[index])\n","      labels.append(labels2[index])\n","\n","  save_dataset(text, labels, output_filename)\n","\n","  # Sample three lines to check for consistency\n","  print('Sampling dataset combination')\n","  print(text[0], labels[0])\n","  print(text[1], labels[1])\n","  print(text[2], labels[2])"]},{"cell_type":"markdown","source":["Now, we generate the datasets that we want."],"metadata":{"id":"CwD1gaT1mOEr"}},{"cell_type":"code","source":["reverse_dataset('Video_Games_Clean.json', 'Video_Games_Reverse.json')\n","shuffle_dataset('Video_Games_Clean.json', 'Video_Games_Shuffle.json')\n","truncate_dataset(500, 'Video_Games_Clean.json', 'Video_Games_Truncate.json')\n","combine_datasets_2('Video_Games_Clean.json', 'Financial_Clean.json',\n","                   'Video_Games_Financial_Combination.json')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WXMbJvb-mNxO","executionInfo":{"status":"ok","timestamp":1701155034831,"user_tz":480,"elapsed":109666,"user":{"displayName":"Austin Chen","userId":"06999593592342824043"}},"outputId":"4007d295-7da8-4ce8-bec3-0f05946be884"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Sampling reversed dataset\n","['great', 'when', 'but', 'of', 'hang', 'get', 'to', 'hard', 'bit', 'game'] 2\n","Sampling shuffled dataset\n","['but', 'to', 'hard', 'when', 'hang', 'of', 'great', 'get', 'game', 'bit'] 2\n","Sampling truncated dataset\n","['game', 'bit', 'hard', 'to', 'get', 'hang', 'of', 'but', 'when', 'great'] 2\n","Comparing sizes, Before: 994, After: 496756\n","Sampling dataset combination\n","['game', 'bit', 'hard', 'to', 'get', 'hang', 'of', 'but', 'when', 'great'] 2\n","['technopolis', 'plan', 'to', 'develop', 'in', 'stage', 'area', 'of', 'no', 'le', 'than', '100000', 'square', 'meter', 'in', 'order', 'to', 'host', 'company', 'working', 'in', 'computer', 'technology', 'and', 'telecommunication', 'statement', 'said'] 1\n","['ok', 'game'] 1\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"y1DMo16bvCfa"},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4,"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}