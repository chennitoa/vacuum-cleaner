{"cells":[{"cell_type":"markdown","source":["# Preproccessing the Financial Phrasebank Dataset"],"metadata":{"id":"VXOXpR0bkcIX"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pseZ_bAYdphz","executionInfo":{"status":"ok","timestamp":1701032952780,"user_tz":480,"elapsed":23339,"user":{"displayName":"Austin Chen","userId":"06999593592342824043"}},"outputId":"235661f0-9f85-4fbf-95e9-3e93d5381cc8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vtnhhXebdmrL"},"outputs":[],"source":["import json\n","import os\n","import string\n","import nltk"]},{"cell_type":"code","source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Remove punctuation from the text\n","def remove_punctuation(text):\n","  punctuationfree = \"\".join([i for i in text if i not in string.punctuation])\n","  return punctuationfree\n","\n","# Remove stopwords\n","# Slice until 63, keep all negative modifiers\n","stopwords = nltk.corpus.stopwords.words('english')[:63]\n","\n","def remove_stopwords(text):\n","  output = [i for i in text if i not in stopwords]\n","  return output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rFCLV3KreJ-X","executionInfo":{"status":"ok","timestamp":1701033232718,"user_tz":480,"elapsed":2100,"user":{"displayName":"Austin Chen","userId":"06999593592342824043"}},"outputId":"f15f5320-eb69-4cb7-d0d7-2da655917aef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}]},{"cell_type":"code","source":["def process_text(rating, text):\n","  if rating == 'negative':\n","    sentiment = 0\n","  elif rating == 'neutral':\n","    sentiment = 1\n","  else:\n","    sentiment = 2\n","\n","  text = remove_punctuation(text).lower().replace('\\n', ' ')\n","  tokens = nltk.word_tokenize(text)\n","  tokens = remove_stopwords(tokens)\n","\n","  wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n","  lemmatized_text = [wordnet_lemmatizer.lemmatize(word) for word in tokens]\n","\n","  return (lemmatized_text, sentiment)"],"metadata":{"id":"uKFddc_heL0H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we import the data from Google Drive."],"metadata":{"id":"02ru9q6Md4Tz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sfNFeWA3dmrO"},"outputs":[],"source":["folder = '/content/drive/MyDrive/CS 171/Final Project'\n","filename = 'Sentences_50Agree.txt'\n","cleaned_filename = 'Financial_Clean.json'"]},{"cell_type":"markdown","source":["With all utility functions defined, we can now preprocess the data."],"metadata":{"id":"D820w2nUeQQb"}},{"cell_type":"code","source":["dataset = []\n","\n","with open(os.path.join(folder, filename), 'r', errors='ignore') as infile:\n","    for line in infile.readlines():\n","      review = line.split('@')\n","\n","      text, sentiment = process_text(review[1].strip(), review[0].strip())\n","\n","      if len(text) != 0:\n","        dataset.append((text, sentiment))"],"metadata":{"id":"3zr7m7t5eFHp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, we re-export the data as a json."],"metadata":{"id":"JrvQ6RS2ee0D"}},{"cell_type":"code","source":["with open(os.path.join(folder, cleaned_filename), 'w') as outfile:\n","  for text, sentiment in dataset:\n","    entry_dict = {'text': text, 'sentiment': sentiment}\n","    json.dump(entry_dict, outfile)\n","    outfile.write('\\n')"],"metadata":{"id":"m4hxZGhwebXr"},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"orig_nbformat":4,"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}